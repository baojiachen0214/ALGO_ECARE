{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 导入人脸关键点检测模型\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "model = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,# 是否是静态图片\n",
    "    refine_landmarks=True,\n",
    "    max_num_faces=5,# 最大人脸数量\n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "# 导入可视化函数和可视化样式\n",
    "mp_drawing = mp.solutions.drawing_utils # 画关键点\n",
    "# 关键点可视化样式\n",
    "landmark_drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=2,color=(66, 77, 229))\n",
    "# 轮廓可视化样式\n",
    "contour_drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1,color=(223, 155,6))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba532a41427c6239"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from seetaface.api import *\n",
    "# 人脸识别比对，返回两张图片的相似度\n",
    "def face_recognition(recognize_frame, character):\n",
    "    # 启用多个功能人脸检测、人脸识别和关键点标记\n",
    "    init_mask = FACE_DETECT|FACERECOGNITION|LANDMARKER5\n",
    "    seetaface = SeetaFace(init_mask)\n",
    "\n",
    "     # 提取识别的人脸特征\n",
    "    detect_result1 = seetaface.Detect(recognize_frame) \n",
    "    face1 = detect_result1.data[0].pos #脸部位置信息face1\n",
    "    points1 = seetaface.mark5(recognize_frame, face1) # 标记face1区域的5个关键点\n",
    "    feature1 = seetaface.Extract(recognize_frame, points1) # 关键点的脸部特征提取\n",
    "    \n",
    "    # 人脸数据比对\n",
    "    detect_result2 = seetaface.Detect(character)\n",
    "    face2 = detect_result2.data[0].pos\n",
    "    points2 = seetaface.mark5(character,face2)\n",
    "    feature2 = seetaface.Extract(character,points2)\n",
    "    \n",
    "    #计算两个特征值的形似度\n",
    "    similar = seetaface.CalculateSimilarity(feature1,feature2)\n",
    "    \n",
    "    return similar"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea02072231dacc7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from seetaface.api import *\n",
    "# 人脸追踪\n",
    "def face_recognition_track(image):\n",
    "    init_mask = FACE_DETECT\n",
    "    seetaFace = SeetaFace(init_mask)\n",
    "    \n",
    "    # 设置最小检测人脸大小\n",
    "    seetaFace.SetProperty(DetectProperty.PROPERTY_MIN_FACE_SIZE,80)\n",
    "    # 设置最小检测人脸阈值0.9，大于0.9得分的人脸才返回\n",
    "    seetaFace.SetProperty(DetectProperty.PROPERTY_THRESHOLD,0.9)\n",
    "    \n",
    "    # 检测图像中的人脸位置\n",
    "    detect_result = seetaFace.Detect(image)\n",
    "    \n",
    "    # 返回一个SeetaFaceInfoArray类型的数据\n",
    "    return detect_result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6bf08109080b8b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 眼间距离（去不同像素下的尺寸对比值）\n",
    "def relative_unit_distance(img,results, retract):\n",
    "     # 获取图像的宽高\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    # 相对不动点距离\n",
    "    stable_point1 = results.multi_face_landmarks[retract].landmark[133]\n",
    "    stable_point2 = results.multi_face_landmarks[retract].landmark[362]\n",
    "    stable_numpy_point1 = np.array([stable_point1.x * w, stable_point1.y * h, stable_point1.z])\n",
    "    stable_numpy_point2 = np.array([stable_point2.x * w, stable_point2.y * h, stable_point2.z])\n",
    "    \n",
    "    # 引入容差值进行比较，防止相对不动点的距离过小\n",
    "    tolerance = 1e-6\n",
    "    if np.allclose(stable_numpy_point1, stable_numpy_point2, atol=tolerance):\n",
    "        return 1.0\n",
    "    else:\n",
    "        return np.linalg.norm(stable_numpy_point1 - stable_numpy_point2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48a8bcd0af343d72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 计算两个关键点之间的距离\n",
    "import numpy as np\n",
    "\n",
    "def distance_landmark(img,results, retract, point_id1, point_id2):\n",
    "    # 获取图像的宽高\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    # 获取指定面部的两个关键点的坐标\n",
    "    landmark1 = results.multi_face_landmarks[retract].landmark[point_id1]\n",
    "    landmark2 = results.multi_face_landmarks[retract].landmark[point_id2]\n",
    "\n",
    "    # 将 landmark 的 x, y, z 转化为 numpy 数组\n",
    "    point1 = np.array([landmark1.x * w, landmark1.y * h, landmark1.z])\n",
    "    point2 = np.array([landmark2.x * w, landmark2.y * h, landmark2.z])\n",
    "    \n",
    "    # 计算欧式距离\n",
    "    dist = np.linalg.norm(point1 - point2)\n",
    "    \n",
    "    return dist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6aa79721aa0658c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 计算点到平面的距离\n",
    "import numpy as np\n",
    "\n",
    "# 计算点到平面的距离\n",
    "def point_to_plane_distance(plane_normal, plane_point, point):\n",
    "    dist = np.dot(plane_normal, (point - plane_point)) / np.linalg.norm(plane_normal)\n",
    "    return np.abs(dist)\n",
    "\n",
    "# 计算plane_point_id1, plane_point_id2, plane_point_id3构成的平面与点集point_id_list的距离\n",
    "def distance_to_plane(img, results, retract, plane_point_id1, plane_point_id2, plane_point_id3, point_id_list):\n",
    "    # 获取图像的宽高\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "\n",
    "    # 获取三个定义平面的点的坐标\n",
    "    landmark1 = results.multi_face_landmarks[retract].landmark[plane_point_id1]\n",
    "    landmark2 = results.multi_face_landmarks[retract].landmark[plane_point_id2]\n",
    "    landmark3 = results.multi_face_landmarks[retract].landmark[plane_point_id3]\n",
    "\n",
    "    # 将 landmark 的 x, y, z 坐标转化为 numpy 数组并调整比例\n",
    "    point1 = np.array([landmark1.x * w, landmark1.y * h, landmark1.z])\n",
    "    point2 = np.array([landmark2.x * w, landmark2.y * h, landmark2.z])\n",
    "    point3 = np.array([landmark3.x * w, landmark3.y * h, landmark3.z])\n",
    "\n",
    "    # 计算平面的法向量\n",
    "    v1 = point2 - point1\n",
    "    v2 = point3 - point1\n",
    "    \n",
    "    # 使用np.array_equal来比较两个数组是否完全相等\n",
    "    if np.array_equal(v1, v2):\n",
    "        return None\n",
    "    else:\n",
    "        plane_normal = np.cross(v1, v2)\n",
    "\n",
    "    # 计算每个点到平面的距离\n",
    "    distances = []\n",
    "    for point_id in point_id_list:\n",
    "        landmark = results.multi_face_landmarks[retract].landmark[point_id]\n",
    "        point = np.array([landmark.x * w, landmark.y * h, landmark.z])\n",
    "        dist = point_to_plane_distance(plane_normal, point1, point)\n",
    "        distances.append(dist)\n",
    "\n",
    "    return np.array(distances)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b3b717040e3f72e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 计算点集到直线的距离\n",
    "import numpy as np\n",
    "\n",
    "def point_to_line_distance(line_point1, line_point2, point):\n",
    "    # 计算点到直线的距离\n",
    "    line_vec = line_point2 - line_point1\n",
    "    point_vec = point - line_point1\n",
    "    # 计算投影点到线段的垂直距离\n",
    "    distance = np.linalg.norm(np.cross(line_vec, point_vec)) / np.linalg.norm(line_vec)\n",
    "    return distance\n",
    "\n",
    "def distance_to_line(img, results, retract, start_point_id, end_point_id, point_id_list):\n",
    "    # 获取图像的宽高\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "\n",
    "    # 获取直线的两个点的坐标\n",
    "    landmark1 = results.multi_face_landmarks[retract].landmark[start_point_id]\n",
    "    landmark2 = results.multi_face_landmarks[retract].landmark[end_point_id]\n",
    "\n",
    "    # 将 landmark 的 x, y, z 坐标转化为 numpy 数组并调整比例\n",
    "    line_point1 = np.array([landmark1.x * w, landmark1.y * h, landmark1.z])\n",
    "    line_point2 = np.array([landmark2.x * w, landmark2.y * h, landmark2.z])\n",
    "\n",
    "    # 计算每个点到直线的距离\n",
    "    distances = []\n",
    "    for point_id in point_id_list:\n",
    "        landmark = results.multi_face_landmarks[retract].landmark[point_id]\n",
    "        point = np.array([landmark.x * w, landmark.y * h, landmark.z])\n",
    "        dist = point_to_line_distance(line_point1, line_point2, point)\n",
    "        distances.append(dist)\n",
    "\n",
    "    return np.array(distances)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82bc5581f5c5018d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 绘制红色重点标记点\n",
    "def show_point(img, results, retract, point_id):\n",
    "    # 获取图像的宽高\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    # 获取指定关键点的坐标\n",
    "    x = int(results.multi_face_landmarks[retract].landmark[point_id].x * w)\n",
    "    y = int(results.multi_face_landmarks[retract].landmark[point_id].y * h)\n",
    "    img = cv2.circle(img, (x,y), 5, (0,0,255), -1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def show_points(img, results, retract, point_id_list):\n",
    "    for point_id in point_id_list:\n",
    "        img = show_point(img, results, retract, point_id)\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a8de9ac9592c26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 导入基础库\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# 定义可视化图像\n",
    "def look_img(img):\n",
    "    # opencv读入的图像格式为BGR，而matplotlib的imshow函数需要RGB格式，因此需要转换下格式\n",
    "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_RGB)\n",
    "    plt.show()\n",
    "    \n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# 测试\n",
    "model = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True, # 是否为静态图片，如果是，则每次输入的图片必须相同尺寸\n",
    "    refine_landmarks=True, # 使用 Attention Mesh 模型，对眼睛、瞳孔周围的关键点精细定位\n",
    "    min_detection_confidence=0.5, # 置信度阈值，越接近 1 越准确\n",
    "    min_tracking_confidence=0.5 # 追踪成功率阈值，越接近 1 越准确\n",
    ")\n",
    "    \n",
    "# 导入可视化函数和可视化样式\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "img = cv2.imread('../users_database/baojiachen.jpg')\n",
    "\n",
    "# 获取图像的宽高\n",
    "h, w = img.shape[0], img.shape[1]\n",
    "\n",
    "# BGR to RGB\n",
    "img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 将RGB图像输入模型，并得到检测结果\n",
    "results = model.process(img_RGB)\n",
    "\n",
    "a = distance_landmark(img,results, 0, 246, 7)\n",
    "\n",
    "print(a)\n",
    "\n",
    "show_point(img, results, 0, 33)\n",
    "show_point(img, results,0,133)\n",
    "\n",
    "# 测试点集到平面的距离\n",
    "lists = [246, 161, 160, 159, 158, 157,173,133]\n",
    "show_points(img, results, 0, lists)\n",
    "distances1 = distance_to_plane(img, results, 0, 246, 133, 197, lists)\n",
    "print(distances1)\n",
    "distances2 = distance_to_line(img, results, 0, 246,133, lists)\n",
    "print(distances2)\n",
    "\n",
    "\n",
    "look_img(img)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a3d2e02649aacd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 判断是否闭眼\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba87d621657d1413"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 处理单帧的函数\n",
    "def process_frame(img):\n",
    "    # 记录该祯开始处理的时间\n",
    "    t0 = time.time()\n",
    "    scaler = 1 # 文字大小\n",
    "    \n",
    "    # 获取图像的宽高\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    # BGR to RGB\n",
    "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 将RGB图像输入模型，并得到检测结果\n",
    "    results = model.process(img_RGB)\n",
    "    \n",
    "    # 如果有检测到人脸，则开始绘制人脸曲面和重点区域轮廓线\n",
    "    if results.multi_face_landmarks: # 如果有检测到人脸\n",
    "        for face_landmarks in results.multi_face_landmarks: # 遍历每一张人脸\n",
    "            # 绘制人脸轮廓线\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=img, # 输入图像\n",
    "                landmark_list=face_landmarks, # 关键点\n",
    "                connections=mp_face_mesh.FACEMESH_CONTOURS, # 连接点\n",
    "                landmark_drawing_spec=landmark_drawing_spec,# 关键点样式,默认为None\n",
    "                connection_drawing_spec=contour_drawing_spec # 连接点样式\n",
    "           )\n",
    "            \n",
    "            # 遍历关键点，添加序号\n",
    "            for idx,coord in enumerate(face_landmarks.landmark):# 遍历关键点\n",
    "                cx = int(coord.x * w)\n",
    "                cy = int(coord.y * h)\n",
    "                # 图片、添加的文字、左上角的坐标、字体、字体大小、颜色、字体粗细\n",
    "                img = cv2.putText(img, 'Face Detected', (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 1)\n",
    "                img = cv2.putText(img, str(idx), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.3 * scaler, (0, 255, 0), 1)\n",
    "    else:\n",
    "        # 如果没有检测到人脸，则提示\n",
    "        # No face detected的提示只能是英文，否则会显示?????\n",
    "        img = cv2.putText(img, 'No face detected!', (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        \n",
    "    # 记录该帧处理完毕的时间\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1 / (t1 - t0)\n",
    "    \n",
    "    img = cv2.putText(img, 'FPS: '+ str(int(FPS)), (25 * scaler, 100 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255))\n",
    "    \n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e00e70a42f1df863"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "46fd67432e93135a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 处理单帧的函数（结合面部的识别）\n",
    "def process_frame2(img):\n",
    "    # 记录该祯开始处理的时间\n",
    "    t0 = time.time()\n",
    "    scaler = 1 # 文字大小\n",
    "    \n",
    "    # 匹配人脸数据\n",
    "    img1=cv2.imread(\"../users_database/baojiachen.jpg\")\n",
    "    \n",
    "    # 获取图像的宽高\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    # BGR to RGB\n",
    "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 将RGB图像输入模型，并得到检测结果\n",
    "    results = model.process(img_RGB)\n",
    "    \n",
    "    # 如果有检测到人脸，则开始绘制人脸曲面和重点区域轮廓线\n",
    "    if results.multi_face_landmarks: # 如果有检测到人脸\n",
    "        for face_landmarks in results.multi_face_landmarks: # 遍历每一张人脸\n",
    "            # 绘制人脸轮廓线\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=img, # 输入图像\n",
    "                landmark_list=face_landmarks, # 关键点\n",
    "                connections=mp_face_mesh.FACEMESH_CONTOURS, # 连接点\n",
    "                landmark_drawing_spec=landmark_drawing_spec,# 关键点样式,默认为None\n",
    "                connection_drawing_spec=contour_drawing_spec # 连接点样式\n",
    "           )\n",
    "            \n",
    "            # 人脸识别\n",
    "            similar = face_recognition(img_RGB,img1)\n",
    "            \n",
    "            # 遍历关键点，添加序号\n",
    "            for idx,coord in enumerate(face_landmarks.landmark):# 遍历关键点\n",
    "                cx = int(coord.x * w)\n",
    "                cy = int(coord.y * h)\n",
    "                # 图片、添加的文字、左上角的坐标、字体、字体大小、颜色、字体粗细\n",
    "                img = cv2.putText(img, 'Face Detected', (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 1)\n",
    "                img = cv2.putText(img, str(idx), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.3 * scaler, (0, 255, 0), 1)\n",
    "    else:\n",
    "        # 如果没有检测到人脸，则提示\n",
    "        # No face detected的提示只能是英文，否则会显示?????\n",
    "        img = cv2.putText(img, 'No face detected!', (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        \n",
    "    # 记录该帧处理完毕的时间\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1 / (t1 - t0)\n",
    "    \n",
    "    img = cv2.putText(img, 'FPS: '+ str(int(FPS)), (25 * scaler, 100 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255))\n",
    "    \n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d8e7cdf3ec96f9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 测试面部识别模块\n",
    "img1=cv2.imread(\"../asserts/seeta1.jpg\")\n",
    "img2=cv2.imread(\"../asserts/seeta2.jpg\")\n",
    "face_recognition(img1,img2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "171c9e5eb8706dce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 测试模块——用于测试人脸识别模块\n",
    "detect_result = face_recognition_track(img1)\n",
    "for i in range(detect_result.size):\n",
    "    face = detect_result.data[i].pos\n",
    "    cv2.rectangle(img1, (face.x, face.y), (face.x + face.width, face.y + face.height), (255, 0, 0),2)\n",
    "\n",
    "cv2.imshow(\"s\",img1)\n",
    "cv2.waitKey(0) # 等待键盘输入"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16b81cbaccd4a1c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 测试模块——用于测试识别结果是否正确输出\n",
    "# 调用摄像头获取每帧\n",
    "# 导入opencv读取视频的库\n",
    "import cv2\n",
    "import time\n",
    "from seetaface.api import *\n",
    "\n",
    "try:\n",
    "    # 获取摄像头，传入0表示获取系统默认摄像头。如果是MacOS，则需要传入1\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # 打开capture\n",
    "    cap.open(0)\n",
    "\n",
    "    # 限制人脸识别的频率\n",
    "    frame_counts = 0\n",
    "    \n",
    "    # 匹配人脸数据\n",
    "    img=cv2.imread(\"../users_database/baojiachen.jpg\")\n",
    "\n",
    "    # 无线循环，直至断开连接\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Ignoring empty\")\n",
    "            break\n",
    "        # 人脸识别\n",
    "        if frame_counts % 120 == 0:\n",
    "            similar = face_recognition(frame,img)\n",
    "            print(similar) # 输出相似度\n",
    "            frame_counts = 0\n",
    "            \n",
    "        #增加帧计数    \n",
    "        frame_counts += 1\n",
    "        \n",
    "        # 处理帧\n",
    "        frame = process_frame(frame)\n",
    "        \n",
    "        # 显示处理后的帧\n",
    "        cv2.imshow('frame', frame)\n",
    "    \n",
    "        # 等待键盘输入，27为esc键，ord用于将字符转为ASCII码\n",
    "        if cv2.waitKey(1) in [27, ord('q')]:\n",
    "            break\n",
    "except Exception as e:\n",
    "    print(\"Error!\")\n",
    "finally: \n",
    "    # 释放摄像头\n",
    "    cap.release()\n",
    "    \n",
    "    # 关闭所有窗口\n",
    "    cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "797a66f90d868b67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 仅作面部分割，不做人脸识别\n",
    "# 调用摄像头获取每帧\n",
    "# 导入opencv读取视频的库\n",
    "import cv2\n",
    "import time\n",
    "from seetaface.api import *\n",
    "\n",
    "# 获取摄像头，传入0表示获取系统默认摄像头。如果是MacOS，则需要传入1\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 打开capture\n",
    "cap.open(0)\n",
    "\n",
    "# 无线循环，直至断开连接\n",
    "while cap.isOpened():\n",
    "    # 读取摄像头数据\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Ignoring empty\")\n",
    "        break\n",
    "        \n",
    "    # 处理帧\n",
    "    frame = process_frame(frame)\n",
    "    \n",
    "    # 显示处理后的帧\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # 等待键盘输入，27为esc键，ord用于将字符转为ASCII码\n",
    "    if cv2.waitKey(1) in [27, ord('q')]:\n",
    "        break\n",
    "        \n",
    "# 释放摄像头\n",
    "cap.release()\n",
    "\n",
    "# 关闭所有窗口\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe479043a655085b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cad8a97b94d83bdb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
